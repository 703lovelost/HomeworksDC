{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf0aDeWFJAvt"
      },
      "source": [
        "# Лабораторная работа №2. Обработка датасета\n",
        "\n",
        "В прошлой работе мы познакомились с консольными командами и менеджерами для установки различного функционала в проект. Начиная с этой лабораторной, мы плавно погружаемся в процесс обучения нейронных сетей.\n",
        "\n",
        "За любым методом машинного обучения стоит некоторая статистика, а за любой статистикой стоят некоторые оцениваемые объекты. Они могут иметь разные характеристики, могут подлежать различной обработке, но без них не достичь никакого результата.\n",
        "\n",
        "**Сразу запоминаем несколько важных условий, серьезно влияющих на применение статистики:**\n",
        "\n",
        "1. Статистики из одного объекта не бывает.\n",
        "1. Статистика по двум объектам составляется только из их прямой зависимости друг от друга => нельзя оценить разнообразие.\n",
        "1. Объекты, кардинально отличающиеся от остальных, могут препятствовать корректности общей статистики.\n",
        "1. Если объекты можно условно разделить на несколько независимых категорий, то зависимость по ним будет строится, исходя из средних значений их признаков (т.н. центров масс множеств).\n",
        "1. При нестандартной (нелинейной) зависимости объектов друг от друга необходимо соблюдать закон, по которому они представлены.\n",
        "\n",
        "На изображении ниже вы можете видеть визуализацию каждого случая, представленного в списке.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/703lovelost/HomeworksDC/refs/heads/main/src/lab2/statistic_plots.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptiUCmi3SnHo"
      },
      "source": [
        "Уточним еще один важный момент: представим, что существуют многомерные представления объектов, не имеющие за собой математической закономерности, но для которых использовался некоторый ассоциативный ряд. К таким представлениям относятся изображения и аудиозаписи. Человек может явно описать их содержание (например, увидеть собаку на фотографии или услышать шум автомобиля в аудиозаписи). Однако если разложить изображение на пиксели, либо аудиозапись на фрагменты цифрового сигнала, то определить действительные закономерности с помощью методов ML становится очень сложно.\n",
        "\n",
        "<img src=\"https://wallpapers.com/images/high/puppy-pictures-umqvikc7wzgxzc9w.webp\">\n",
        "\n",
        "Последующие открытия в данном вопросе привели к появлению Deep Learning - методов глубокого машинного обучения, позволяющих эффективно рассматривать контекст данных и обобщать их для решения конкретных задач, таких как:\n",
        "\n",
        "* Классификация - определение принадлежности объекта к одному/нескольким рассматриваемым наименованиям;\n",
        "* Сегментация - разметка (н-ер, пикселей изображений) в соответствии с рассматриваемыми наименованиями;\n",
        "* Детекция - определение зон нахождения объектов, включая их классификацию."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExEt2KTuuKYW"
      },
      "source": [
        "## Задание 1.\n",
        "\n",
        "Настало время вспомнить опыт предыдущей работы и загрузить свой первый датасет для исследования.\n",
        "\n",
        "Для поиска датасетов используется сервис Kaggle. Именно с него мы возьмем наш первый [датасет, в котором представлены изображения 10 различных видов цветов.](https://www.kaggle.com/datasets/aksha05/flower-image-dataset) Скачаем и разархивируем его.\n",
        "\n",
        "После каждой запущенной ячейки не забывайте обновлять вкладку _Files_ в меню слева, либо запускать аналогичную команду `cd`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPURhvHKTEvm"
      },
      "outputs": [],
      "source": [
        "# Все, что начинается после знака штрихкода - это комментарий к коду/скрипту в ячейке.\n",
        "# cURL - прекрасный способ выгрузить любую информацию из интернета, в том числе скачать необходимые вам файлы.\n",
        "# Так можно выгружать даже веб-страницы. Попробуйте как-нибудь выгрузить HTML-разметку главной страницы Google (google.com).\n",
        "\n",
        "!curl -L -o ./flower-image-dataset.zip https://www.kaggle.com/api/v1/datasets/download/aksha05/flower-image-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXPU2tQVTOLU"
      },
      "outputs": [],
      "source": [
        "# unzip - классический пакет Linux для разархивирования файлов. Есть и другие, но он стандартный и легко устанавливается.\n",
        "\n",
        "!unzip -q ./flower-image-dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m50G773-sxnw"
      },
      "source": [
        "## Задание 2.\n",
        "\n",
        "У вас появилась папка _flowers_. Откроем ее и увидим дикую кучу файлов.\n",
        "\n",
        "В любом датасете важна правильная организация файлов, с которой вы получите ряд преимуществ:\n",
        "\n",
        "* Значительно упростится навигация по файлам.\n",
        "* Появится возможность управлять отдельными рядами файлов - например, обогащать отдельные классы, об этом чуть позже.\n",
        "* Снизится к нулю вероятность \"утечки данных\", когда объекты в ходе обучения модели были применены не по назначению.\n",
        "\n",
        "Мы видим, что в скачанном датасете цветы _хотя бы подписаны_ (еще такие подписи называются лейблами, дальше я буду называть их так). Это нам уже значительно упрощает упорядочивание.\n",
        "\n",
        "Сейчас мы с вами займемся сортировкой файлов по папкам в соответствии с их лейблами. Подготовим наш код. Запустите ячейку ниже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5JOei4ny0Oo"
      },
      "outputs": [],
      "source": [
        "# Импорт библиотек Python для использования в коде.\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from typing import Dict, Iterable, List, Tuple, Optional\n",
        "\n",
        "# Константы - постоянные значения.\n",
        "\n",
        "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\", \".tif\", \".tiff\", \".webp\"}\n",
        "\n",
        "# Немного функций общего пользования.\n",
        "\n",
        "def is_image(path: Path) -> bool:\n",
        "    return path.is_file() and path.suffix.lower() in IMG_EXTS and not path.name.startswith(\"._\")\n",
        "\n",
        "def extract_label_from_filename(fname: str) -> str:\n",
        "    stem = Path(fname).stem\n",
        "    return stem.rsplit(\"_\", 1)[0] if \"_\" in stem else stem\n",
        "\n",
        "def ensure_empty_dir(p: Path, force: bool = False) -> None:\n",
        "    if p.exists():\n",
        "        if force:\n",
        "            shutil.rmtree(p)\n",
        "        else:\n",
        "            raise FileExistsError(f\"Папка уже существует: {p}. Укажите force=True для перезаписи.\")\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def uniquify(dst: Path) -> Path:\n",
        "    if not dst.exists():\n",
        "        return dst\n",
        "    stem, ext = dst.stem, dst.suffix\n",
        "    i = 1\n",
        "    while True:\n",
        "        cand = dst.with_name(f\"{stem}__dup{i}{ext}\")\n",
        "        if not cand.exists():\n",
        "            return cand\n",
        "        i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ye-ULHBtRA8"
      },
      "source": [
        "__Важно: если в проекте Google Colab ранее была запущена ячейка с импортами, то она будет применена ко всем остальным ячейкам.\n",
        "Более того, все ячейки сохраняют контекст ранее запущенных ячеек.__\n",
        "\n",
        "__Номер запуска ячейки вы можете найти в квадратных скобках слева от любой исполняемой ячейки.__\n",
        "\n",
        "При запуске ячеек пока еще ничего не происходит, кроме подгрузки в среду библиотек, констант и функций.\n",
        "\n",
        "Ниже идет сама функция для преобразования папки _flowers_ в нужный нам формат. Запустите ячейку."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrqOkycZ15Q-"
      },
      "outputs": [],
      "source": [
        "def classify_flowers(\n",
        "    src_dir: Path | str = \"flowers\",\n",
        "    out_dir: Path | str = \"flowers_classified\",\n",
        "    *,\n",
        "    force: bool = False,\n",
        "    return_manifest: bool = True,\n",
        "):\n",
        "    src_dir = Path(src_dir)\n",
        "    out_dir = Path(out_dir)\n",
        "\n",
        "    if not src_dir.exists():\n",
        "        raise FileNotFoundError(f\"Исходная папка не найдена: {src_dir}\")\n",
        "\n",
        "    ensure_empty_dir(out_dir, force=force)\n",
        "\n",
        "    files = [p for p in src_dir.rglob(\"*\") if is_image(p)]\n",
        "    if not files:\n",
        "        raise RuntimeError(f\"В {src_dir} не найдено изображений с расширениями: {sorted(IMG_EXTS)}\")\n",
        "\n",
        "    per_class_counts: Dict[str, int] = {}\n",
        "    manifest: List[Dict[str, str]] = []\n",
        "\n",
        "    for f in files:\n",
        "        label = extract_label_from_filename(f.name)\n",
        "        class_dir = out_dir / label\n",
        "        class_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        dst = uniquify(class_dir / f.name)\n",
        "        shutil.copy2(f, dst)\n",
        "\n",
        "        per_class_counts[label] = per_class_counts.get(label, 0) + 1\n",
        "        if return_manifest:\n",
        "            manifest.append({\"src\": str(f), \"dst\": str(dst), \"label\": label})\n",
        "\n",
        "    # Краткая сводка\n",
        "    total = sum(per_class_counts.values())\n",
        "    n_classes = len(per_class_counts)\n",
        "    print(f\"Всего файлов: {total} | Классов: {n_classes}\")\n",
        "    for k in sorted(per_class_counts):\n",
        "        print(f\"  {k}: {per_class_counts[k]}\")\n",
        "\n",
        "    return manifest if return_manifest else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUMEFQIUtEZW"
      },
      "source": [
        "Теперь перейдем к главному зрелищу. Ячейка ниже позволяет, наконец, запустить процесс сортировки. Не томите, запускайте :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaxKGOR8smAw",
        "outputId": "31806d4d-04b3-4580-84ac-ab5c42d4bba0"
      },
      "outputs": [],
      "source": [
        "manifest = classify_flowers(src_dir=\"./flowers\", out_dir=\"./flowers_classified\", force=True, return_manifest=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aydLSLKu0lj"
      },
      "source": [
        "По результатам вывода мы можем видеть, сколько изображений представлено для каждого вида - они все достаточно представлены, датасет хорошо сбалансирован.\n",
        "\n",
        "Также мы можем непосредственно доказать, что там действительно 10 видов (классов). Это нам и требовалось.\n",
        "\n",
        "Результат можно также посмотреть в ваших файлах в папке _flowers_classified_. Согласитесь, другое дело."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqFutsM5vkJ7"
      },
      "source": [
        "## Задание 3.\n",
        "\n",
        "Теперь настало время для серьезного разговора.\n",
        "\n",
        "Данные для обучения делятся на три типа:\n",
        "\n",
        "* Обучающие данные (training data) - выборка из датасета для знакомства модели с объектами и для выделения свойств. Модель калибруется под выделение тех или иных признаков в объектах для дальнейшей работы с ними.\n",
        "* Валидационные данные (validation data) - выборка из датасета для уточнения качества обучения модели. При прохождении валидационных данных через модель она уже считается откалиброванной, оператор может сам подобрать дополнительные параметры для улучшения обработки моделью.\n",
        "* Тестовые данные (testing data) - данные для проверки итоговой версии модели, не имеющие никакого влияния на ее функциональность. Редко представлены в самом датасете, поскольку нужны либо для непосредственного обучения, либо донастройки.\n",
        "\n",
        "Изображение из датасета может быть только в одной из вышеописанных выборок. Это главное условие для избежания \"утечки данных\".\n",
        "\n",
        "Сейчас мы с вами будем делить датасет на составляющие его выборки, а именно training и validation.\n",
        "\n",
        "Существует два способа это сделать:\n",
        "\n",
        "* Виртуально разделить датасет на подвыборки при подгрузки датасета для обучения (как это делает, например, [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html))\n",
        "* Сразу разделить датасет на соответствующие подпапки.\n",
        "\n",
        "Со вторым пунктом идеально справляется библиотека [splitfolders](https://pypi.org/project/split-folders/). Установим ее."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQy42HzIwNq4",
        "outputId": "6df5aee6-c98f-4fd6-c71e-de239e11696d"
      },
      "outputs": [],
      "source": [
        "!pip install split-folders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sko8s4Mc4K2F"
      },
      "source": [
        "Используя splitfolders, вы сможете наяву посмотреть деление датасета и увидеть всю красоту. Нам в этом также поможет соответствующая функция."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3Z0bUkm1raL"
      },
      "outputs": [],
      "source": [
        "def split_flowers(\n",
        "    classified_dir: Path | str = \"flowers_classified\",\n",
        "    out_split_dir: Path | str = \"flowers_split\",\n",
        "    *,\n",
        "    train_ratio: float = 0.85,\n",
        "    val_ratio: float = 0.15,\n",
        "    seed: int = 42,\n",
        "    force: bool = False,\n",
        "    move: bool = False,\n",
        "):\n",
        "    try:\n",
        "        import splitfolders  # pip install split-folders\n",
        "    except ImportError as e:\n",
        "        raise SystemExit(\"Не найден пакет splitfolders. Установите: pip install split-folders\") from e\n",
        "\n",
        "    classified_dir = Path(classified_dir)\n",
        "    out_split_dir = Path(out_split_dir)\n",
        "\n",
        "    if not classified_dir.exists():\n",
        "        raise FileNotFoundError(f\"Папка с классами не найдена: {classified_dir}\")\n",
        "\n",
        "    if abs((train_ratio + val_ratio) - 1.0) > 1e-6:\n",
        "        raise ValueError(f\"Сумма долей должна быть 1.0, сейчас: {train_ratio + val_ratio}\")\n",
        "\n",
        "    ensure_empty_dir(out_split_dir, force=force)\n",
        "\n",
        "    splitfolders.ratio(\n",
        "        input=str(classified_dir),\n",
        "        output=str(out_split_dir),\n",
        "        seed=seed,\n",
        "        ratio=(train_ratio, val_ratio),\n",
        "        move=move,\n",
        "    )\n",
        "    print(f\"\\ntrain/val = {train_ratio:.2f}/{val_ratio:.2f} → {out_split_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhq1MoYa5Hc0"
      },
      "source": [
        "Соотношения обучающих данных к валидационных подбираются такие, чтобы обучающие значительно превалировали по числу. Обычно берется соотношение 85/15, в особенности, если датасет маленький, как этот.\n",
        "\n",
        "Ну что ж, вперед запускать и смотреть результат у себя в файлах!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT5Quje6wKQ9"
      },
      "outputs": [],
      "source": [
        "split_flowers(\"./flowers_classified\", \"./flowers_split\", train_ratio=0.85, val_ratio=0.15, force=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y54pFUDA5NdX"
      },
      "source": [
        "## Задание 4.\n",
        "\n",
        "Несложно заметить, что есть признаки, которые объединяют определенные виды цветов - как минимум, их расцветки уже могут сбить модель с толку. Не забываем также о том, что датасет в целом маленький, и надо бы как-то его обогатить.\n",
        "\n",
        "Для этого существует такая практика, как [аугментация данных](https://habr.com/ru/companies/smartengines/articles/264677/) - преобразование изображений датасета таким образом, чтобы модель могла лучше выделить одни качества объекта над другими, например, форму над цветом.\n",
        "\n",
        "Принцип работы таков:\n",
        "\n",
        "1. Объявляются методы преобразования картинок перед отправкой на обучение модели. Прописываются вероятности, с которыми те или иные преобразования будут применены.\n",
        "1. Модель обучается, хватая картинки небольшими пачками (т.н. батчами). С некоторой прописанной вероятностью в батч вместо оригинальной картинки будет направлена ее преобразованная версия.\n",
        "\n",
        "Здесь мы рассмотрим такую библиотеку, как [albumentations](https://pypi.org/project/albumentations/) - огромный и удобный в использовании каталог аугментаций для изображений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psp5hXGt8tlj"
      },
      "outputs": [],
      "source": [
        "!pip install albumentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YVHvH9mB5Je"
      },
      "source": [
        "Объявим все необходимое для запуска аугментаций. Замечу, что в данном примере все аугментации будут иметь вероятность в 100%, чтобы вы точно не пропустили ни одну из них."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "UwQ7upxv8x0s"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import random\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "\n",
        "\n",
        "# Немного общих функций.\n",
        "\n",
        "def list_images(folder: str | Path) -> List[Path]:\n",
        "    folder = Path(folder)\n",
        "    if not folder.exists():\n",
        "        raise FileNotFoundError(f\"Папка не найдена: {folder}\")\n",
        "    exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
        "    return [p for p in folder.rglob(\"*\") if p.is_file() and p.suffix.lower() in exts]\n",
        "\n",
        "def imread_rgb(path: Path) -> np.ndarray:\n",
        "    img_bgr = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
        "    if img_bgr is None:\n",
        "        raise ValueError(f\"Не удалось прочитать изображение: {path}\")\n",
        "    return cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# Сами аугментации.\n",
        "\n",
        "def build_aug_transforms(img_size: int = 224) -> Dict[str, A.BasicTransform]:\n",
        "    return {\n",
        "        \"RandomResizedCrop\":  A.RandomResizedCrop(size=(img_size, img_size), scale=(0.75, 1.0), ratio=(0.9, 1.1), p=1.0),\n",
        "        \"HorizontalFlip\":     A.HorizontalFlip(p=1.0),\n",
        "        \"ToGray\":             A.ToGray(method='weighted_average', p=1.0),\n",
        "        \"HueSaturationValue\": A.HueSaturationValue(\n",
        "            hue_shift_limit=[-40, 20], sat_shift_limit=[0, 90], val_shift_limit=[-20, 20], p=1.0\n",
        "        ),\n",
        "        \"CoarseDropout\":      A.CoarseDropout(\n",
        "            hole_height_range=[0.5, img_size // 8],\n",
        "            hole_width_range=[0.5, img_size // 8],\n",
        "            num_holes_range=[1, 4],\n",
        "            fill=0,\n",
        "            p=1.0\n",
        "        ),\n",
        "    }\n",
        "\n",
        "def apply_transforms(img_rgb: np.ndarray, transforms: Dict[str, A.BasicTransform]) -> Dict[str, np.ndarray]:\n",
        "    out = {}\n",
        "    for name, t in transforms.items():\n",
        "        aug = A.Compose([t])\n",
        "        out[name] = aug(image=img_rgb)[\"image\"]\n",
        "    return out\n",
        "\n",
        "# Визуализация.\n",
        "\n",
        "def show_augmentations_grid(\n",
        "    image_paths: List[Path],\n",
        "    transforms: Dict[str, A.BasicTransform],\n",
        "    img_size: int = 224,\n",
        "    max_samples: int = 3,\n",
        "    seed: int = 42,\n",
        "):\n",
        "    set_seed(seed)\n",
        "    if len(image_paths) == 0:\n",
        "        raise RuntimeError(\"Список изображений пуст.\")\n",
        "    sample_paths = random.sample(image_paths, k=min(max_samples, len(image_paths)))\n",
        "\n",
        "    n_aug = len(transforms)\n",
        "    n_cols = n_aug + 1\n",
        "    n_rows = len(sample_paths)\n",
        "\n",
        "    plt.figure(figsize=(3.0 * n_cols, 3.2 * n_rows))\n",
        "\n",
        "    for r, path in enumerate(sample_paths):\n",
        "        img = imread_rgb(path)\n",
        "        base = A.Compose([A.LongestMaxSize(max_size=img_size), A.PadIfNeeded(img_size, img_size, border_mode=cv2.BORDER_CONSTANT, value=(0,0,0))])(image=img)[\"image\"]\n",
        "\n",
        "        ax = plt.subplot(n_rows, n_cols, r * n_cols + 1)\n",
        "        ax.imshow(base)\n",
        "        ax.set_title(\"Original\", fontsize=11)\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "        aug_images = apply_transforms(base, transforms)\n",
        "        for c, (name, aug_img) in enumerate(aug_images.items(), start=2):\n",
        "            ax = plt.subplot(n_rows, n_cols, r * n_cols + c)\n",
        "            ax.imshow(aug_img)\n",
        "            ax.set_title(name, fontsize=11)\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w6Z2WojCCfk"
      },
      "source": [
        "Настало время для итоговой генерации. Запускайте ячейку!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7KEaB-a-XnL"
      },
      "outputs": [],
      "source": [
        "train_images = list_images(\"./flowers_split/train\")\n",
        "\n",
        "augs = build_aug_transforms(img_size=224)\n",
        "show_augmentations_grid(train_images, augs, img_size=224, max_samples=10, seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiRAR8InCbt2"
      },
      "source": [
        "## Задание 5.\n",
        "\n",
        "Разработчики albumentations подготовили сайт, где вы можете попробовать онлайн каждую из представленных аугментаций.\n",
        "\n",
        "[https://explore.albumentations.ai/](https://explore.albumentations.ai/)\n",
        "\n",
        "Ознакомьтесь с аугментациями на сайте.\n",
        "\n",
        "При сдаче работы преподаватель даст вам определенную тему датасета. Будьте готовы назвать 2-3 аугментации, которые вы бы применили, чтобы обогатить датасет и улучшить качество модели по различию классов в датасете."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
